{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb5cdef",
   "metadata": {},
   "source": [
    "# An Analysis of Political Contributions During the 2020 House of Representatives Election\n",
    "\n",
    "In this part, you will obtain as much data as you can on the campaign contributions received by each candidate. This data is available through the website https://www.opensecrets.org/. At the end of the project, your group will give a presentation of your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca94a5",
   "metadata": {},
   "source": [
    "1. Start by scraping the data from the summary page for Tennessee's 2nd District, which is available at https://www.opensecrets.org/races/summary?cycle=2020&id=TN02&spec=N.\n",
    "    * The data that we want is contained in the \"Total Raised and Spent\" table.\n",
    "    * Make a DataFrame showing, for each candidate:\n",
    "        * the candidate's name\n",
    "        * the candidate's party\n",
    "        * state\n",
    "        * district number\n",
    "        * whether the candidate was an incumbent\n",
    "        * whether the candidate won the race\n",
    "        * the total amount raised by that candidate (as a numeric variable)\n",
    "        * the total amount spent by the candidate (as a numeric variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e74bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "from urllib.request import Request, urlopen\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "# URL for TN's second district.\n",
    "Initial_URL = 'https://www.opensecrets.org/races/summary?cycle=2020&id=TN02&spec=N'\n",
    "\n",
    "# Consider whether to add NaNs for candidates for which Open Secrets does not have data.\n",
    "def political_df_creation(URL, error_count = 5):\n",
    "    \"\"\"Function to create dataframe from first table in open secrets link per state district\"\"\"\n",
    "    \n",
    "    # Show that I'm human. Open secrets will generate a captcha webpage otherwise.\n",
    "    request = Request(URL, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(request).read().decode('utf-8')\n",
    "    soup = BS(webpage,'lxml')\n",
    "    \n",
    "    # Create dataframe if table exists. Retry if link doesn't work (up to a point).\n",
    "    district = ''\n",
    "    try:\n",
    "        district = pd.read_html(str(soup.find('table', attrs = {'class' : 'DataTable'})))[0]\n",
    "    except ValueError:\n",
    "        if error_count > 0:\n",
    "            error_count -= 1\n",
    "            political_df_creation(URL, error_count = error_count)\n",
    "        else:\n",
    "            print(f\"{URL} is not working.\")\n",
    "            sys.exit(1) \n",
    "    \n",
    "    def district_df_clean_up(district):\n",
    "        \"\"\"Function to clean up district dataframe.\"\"\"\n",
    "        \n",
    "        # Pull out name, account for hyphenation.\n",
    "        district['Name'] = (\n",
    "            district['Candidate'].\\\n",
    "            str.extract(r'([A-Za-z]+\\s*-*[A-Za-z]*\\s*-*[A-Za-z]+)\\s', expand = True)\n",
    "        )\n",
    "        \n",
    "        # Pull out party.\n",
    "        district['Party'] = (\n",
    "            district['Candidate'].\\\n",
    "            str.extract(r'(\\([A-Z1-9]\\))', expand = True)\n",
    "        )\n",
    "        \n",
    "        # Pull out incumbent value, and set to boolean values.\n",
    "        incumbent = re.compile(r'\\s(Incumbent)')\n",
    "        district['Incumbent'] = ''\n",
    "        for i in district['Candidate']:\n",
    "            if incumbent.search(i):\n",
    "                district['Incumbent'].loc[district['Candidate'] == i] = True\n",
    "            else:\n",
    "                district['Incumbent'].loc[district['Candidate'] == i] = False\n",
    "                \n",
    "        # Pull out winner, set to boolean values.\n",
    "        winner = re.compile(r'\\s(Winner)')\n",
    "        district['Winner'] = ''\n",
    "        for i in district['Candidate']:\n",
    "            if winner.search(i):\n",
    "                district['Winner'].loc[district['Candidate'] == i] = True\n",
    "            else:\n",
    "                district['Winner'].loc[district['Candidate'] == i] = False\n",
    "        \n",
    "        # Drop mashed up column and a couple others.\n",
    "        district = (\n",
    "            district.drop(columns = ['Candidate', 'Cash on Hand', 'Last Report'])\n",
    "        )\n",
    "        \n",
    "        # Set raised and spent columns to numbers.\n",
    "        district['Raised'] = (\n",
    "            district['Raised'].\\\n",
    "            str.replace(',', '', regex = False).\\\n",
    "            str.replace('$', '', regex = False).astype('int64')\n",
    "        )\n",
    "        district['Spent'] = (\n",
    "            district['Spent'].\\\n",
    "            str.replace(',', '', regex = False).\\\n",
    "            str.replace('$', '', regex = False).astype('int64')\n",
    "        )\n",
    "        \n",
    "        # Pull out state and district number from homelink.\n",
    "        homelink = str(soup.find('link', href=True))\n",
    "        state = re.compile(r'id=([A-Z]+)\\d*')\n",
    "        state = state.search(homelink)\n",
    "        district['State'] = state.group(1)\n",
    "\n",
    "        district_number = re.compile(r'id=[A-Z]+(\\d*)')\n",
    "        district_number = district_number.search(homelink)\n",
    "        district['District'] = district_number.group(1)\n",
    "        \n",
    "        # Rearrange columns for readability.\n",
    "        cols = district.columns.tolist()\n",
    "        cols = cols[2:len(cols)+1] + cols [0:2]\n",
    "        district = district[cols]\n",
    "        return district\n",
    "    \n",
    "    district = district_df_clean_up(district)\n",
    "    return district\n",
    "\n",
    "\n",
    "political_df_creation(Initial_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793e19e",
   "metadata": {},
   "source": [
    "2. Once you have working code for Tennessee's 2nd District, expand on your code to capture all of Tennessee's districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "# Cycle through each of the nine TN districts using above functions.\n",
    "for i in range(1,10):\n",
    "    district = (\n",
    "        political_df_creation(f'https://www.opensecrets.org/races/summary?cycle=2020&id=TN0{i}&spec=N')\n",
    "    )\n",
    "    if i == 1:\n",
    "        all_districts = district\n",
    "    else:\n",
    "        all_districts = all_districts.merge(district, how = 'outer')\n",
    "all_districts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bccbd5",
   "metadata": {},
   "source": [
    "3. Once you have working code for all of Tennessee's districts, expand on it to capture all states and districts. The number of representatives each state has can be found in a table on this page: https://www.britannica.com/topic/United-States-House-of-Representatives-Seats-by-State-1787120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcefa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "# Cull abbreviation list from boy scouts website for purposes of full scrape.\n",
    "abbreviations_url = 'https://www.scouting.org/resources/los/states/'\n",
    "request = Request(abbreviations_url, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(request).read().decode('utf-8')\n",
    "soup = BS(webpage,'lxml')\n",
    "abbreviations = pd.read_html(str(soup.find('div', attrs = {'class' : 'table-responsive'})))[0]\n",
    "# Some territories included.\n",
    "abbreviations = abbreviations.loc[~abbreviations['Postal'].isin(['GU', 'PR', 'VI', 'CZ'])].drop(columns = 'Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65351423",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cull number of representatives list for purposes of final scrape.\n",
    "number_of_reps_url = 'https://www.britannica.com/topic/United-States-House-of-Representatives-Seats-by-State-1787120'\n",
    "response = requests.get(number_of_reps_url)\n",
    "soup = BS(response.text)\n",
    "number_of_reps = (\n",
    "    pd.read_html(str(soup.find('table')))[0].\\\n",
    "    rename(columns = {'state':'State', \n",
    "                      'representatives':'Representatives'})\n",
    ")\n",
    "\n",
    "# Merge the two dataframes together.\n",
    "reps_plus_abbreviations = pd.merge(abbreviations, number_of_reps, how = 'outer')\n",
    "reps_plus_abbreviations['Representatives'].loc[reps_plus_abbreviations['Postal'] == 'DC'] = 1\n",
    "reps_plus_abbreviations = reps_plus_abbreviations[:51].astype({'Representatives':'int64'})\n",
    "reps_plus_abbreviations.to_csv(\"Write_Data_Here/reps_plus_abbreviations.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e372434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set enumeration value.\n",
    "e = 0\n",
    "# Cycle through all links for each district.\n",
    "for row in reps_plus_abbreviations.itertuples():\n",
    "    abbrev = row[2]\n",
    "    reps_endpoint = row[3] + 1\n",
    "    # DC is different.\n",
    "    if abbrev != 'DC':\n",
    "        for k in range(1, reps_endpoint):\n",
    "            if k < 10:\n",
    "                url = f'https://www.opensecrets.org/races/summary?cycle=2020&id={abbrev}0{k}&spec=N'\n",
    "                district = political_df_creation(url)\n",
    "            else:\n",
    "                url = f'https://www.opensecrets.org/races/summary?cycle=2020&id={abbrev}{k}&spec=N'\n",
    "                district = political_df_creation(url)\n",
    "            # Set the first district as the base into which all others will merge.\n",
    "            if e == 0:\n",
    "                all_districts = district\n",
    "                e += 1\n",
    "            # Merge everyone else.\n",
    "            else:\n",
    "                all_districts = all_districts.merge(district, how = 'outer')\n",
    "    else:\n",
    "        url = f'https://www.opensecrets.org/races/summary?cycle=2020&id=DC00'\n",
    "        district = political_df_creation(url)\n",
    "        all_districts = all_districts.merge(district, how = 'outer')\n",
    "    # Delay, otherwise will get HTTPS 429 from server.\n",
    "    time.sleep(0.05)\n",
    "# Show dataframe to check.\n",
    "all_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to csv file.\n",
    "all_districts.to_csv(\"Write_Data_Here/all_districts.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4a737",
   "metadata": {},
   "source": [
    "4. Using your scraped data, investigates different relationships between candidates and the amount of money they raised. Here are some suggestions to get you started, but feel free to pose you own questions or do additional exploration:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24723977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "# Read in dataframe and pull info.\n",
    "all_districts = pd.read_csv(\"Write_Data_Here/all_districts.csv\")\n",
    "all_districts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafb6b2",
   "metadata": {},
   "source": [
    "a. How often does the candidate who raised more money win a race?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b45243",
   "metadata": {},
   "source": [
    "b. How often does the candidate who spent more money win a race? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86088861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 4(a) and (b)\n",
    "# Create a groupby dataframe culling the max amounts raised.\n",
    "relevant_columns = ['Raised', 'Spent']\n",
    "\n",
    "for i in relevant_columns:\n",
    "    rtm_amounts = (\n",
    "        pd.DataFrame(all_districts.groupby(['State', 'District'])['Raised'].max()).\\\n",
    "        reset_index().assign(Most = True)\n",
    "    )\n",
    "    # Merge with all_districts.\n",
    "    all_districts = (\n",
    "        all_districts.merge(rtm_amounts, how = 'outer')\n",
    "    )\n",
    "    # Fill in NA values with false since not max values.\n",
    "    all_districts['Most'].loc[all_districts['Most'].isna()] = False\n",
    "    # Run a crosstab and calculate precentage.\n",
    "    percentage = pd.crosstab(all_districts['Winner'], all_districts['Most'])[1][1]/\\\n",
    "    pd.crosstab(all_districts['Winner'], all_districts['Most'])[1].sum()\n",
    "    print(f\"The candidate that {i.lower()} the most money won ~{'{:.0%}'.format(round(percentage,2))} of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cb472",
   "metadata": {},
   "source": [
    "c. Does the difference between either money raised or money spent seem to influence the likelihood of a candidate winning a race? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809c1e4",
   "metadata": {},
   "source": [
    "**Money raised seems to strongly correlate with whether a candidate will win a particular race, but money raised may be a product of notoriety or connections, which may be the real causal factor for winning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15b17f",
   "metadata": {},
   "source": [
    "d. How often does the incumbent candidate win a race?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4(d)\n",
    "# Generate percentage of incumbents who were winners.\n",
    "percentage = pd.crosstab(all_districts['Winner'], all_districts['Incumbent'])[1][1]/\\\n",
    "pd.crosstab(all_districts['Winner'], all_districts['Incumbent'])[1].sum()\n",
    "print(f\"~{'{:.0%}'.format(round(percentage,2))} of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d69fdc",
   "metadata": {},
   "source": [
    "e. Can you detect any relationship between amount of money raised and the incumbent status of a candidate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b2dd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 4(e)\n",
    "# Run a logistic regression on incumbency vs. money raised, but plot inversely.\n",
    "all_districts['Incumbent'] = pd.get_dummies(all_districts['Incumbent'], drop_first = True)\n",
    "all_districts = all_districts.loc[all_districts['Raised'] > 0]\n",
    "\n",
    "x_values = sm.add_constant(np.log(all_districts['Raised']))\n",
    "incumbent_model = sm.Logit(endog = all_districts['Incumbent'], exog = x_values).fit()\n",
    "all_districts['Predicted Values'] = incumbent_model.predict(x_values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.scatterplot('Incumbent', 'Raised', data = all_districts, color = 'blue', ax = ax);\n",
    "sns.lineplot('Predicted Values', 'Raised', data = all_districts, color = 'black', ax = ax);\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.title('Logistic Regression for Incumbent Status and Money Raised');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395484f",
   "metadata": {},
   "source": [
    "**Incumbents are generally able to raise more money, so any consideration of whether raising more money makes a candidate more likely to win needs to account for incumbency as a potential confounding factor.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
